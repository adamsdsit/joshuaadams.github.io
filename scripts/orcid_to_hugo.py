#!/usr/bin/env python3
"""
Fetch public works from ORCID and generate Hugo publication markdown files.

- Reads ORCID iD from env ORCID_ID (default: 0000-0002-7185-9125)
- Writes content/publication/*.md
- Idempotent: deletes & recreates autogenerated files only
"""

from __future__ import annotations

import os
import re
import json
import shutil
import urllib.request
from datetime import date
from pathlib import Path

ORCID_ID = os.getenv("ORCID_ID", "0000-0002-7185-9125").strip()
OUT_DIR = Path("content/publication")
AUTO_TAG = "autogen_orcid"
API_BASE = "https://pub.orcid.org/v3.0"  # ORCID Public API v3.0


def slugify(s: str) -> str:
    s = s.lower().strip()
    s = re.sub(r"[^\w\s-]", "", s)
    s = re.sub(r"[\s_-]+", "-", s)
    return s.strip("-") or "publication"


def http_get_json(url: str) -> dict:
    req = urllib.request.Request(
        url,
        headers={
            "Accept": "application/json",
            "User-Agent": "orcid-to-hugo/1.0 (joshuaadams.dev)",
        },
    )
    with urllib.request.urlopen(req, timeout=30) as resp:
        data = resp.read().decode("utf-8")
    return json.loads(data)


def ensure_clean_outdir():
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    # remove only files we previously generated
    for p in OUT_DIR.glob("*.md"):
        txt = p.read_text(encoding="utf-8", errors="ignore")
        if f"autogen: {AUTO_TAG}" in txt:
            p.unlink()


def safe_year(work: dict) -> str:
    # ORCID sometimes gives year in publication-date->year->value
    pub_date = work.get("publication-date") or {}
    year = ((pub_date.get("year") or {}).get("value")) if isinstance(pub_date, dict) else None
    if year and re.fullmatch(r"\d{4}", str(year)):
        return str(year)
    # fallback
    return str(date.today().year)


def pick_best_title(work_summary: dict) -> str:
    title = (work_summary.get("title") or {}).get("title") or {}
    val = title.get("value") if isinstance(title, dict) else None
    return (val or "Untitled Work").strip()


def extract_external_ids(work_summary: dict) -> dict:
    # returns dict like {"doi": "...", "arxiv": "...", "url": "..."}
    out = {}
    ext = work_summary.get("external-ids") or {}
    ids = ext.get("external-id") if isinstance(ext, dict) else None
    if not ids:
        return out
    if isinstance(ids, dict):
        ids = [ids]
    for item in ids:
        t = (item.get("external-id-type") or "").lower()
        v = (item.get("external-id-value") or "").strip()
        if t and v and t not in out:
            out[t] = v
    # also try external-url
    ext_url = work_summary.get("url") or {}
    if isinstance(ext_url, dict) and ext_url.get("value"):
        out["url"] = ext_url["value"]
    return out


def format_doi_link(doi: str) -> str:
    doi = doi.strip()
    if doi.lower().startswith("http"):
        return doi
    return f"https://doi.org/{doi}"


def main():
    ensure_clean_outdir()

    # Step 1: list works (summaries)
    works = http_get_json(f"{API_BASE}/{ORCID_ID}/works")
    groups = works.get("group") or []

    for g in groups:
        # pick first work-summary as representative for now
        summaries = g.get("work-summary") or []
        if not summaries:
            continue
        ws = summaries[0]

        title = pick_best_title(ws)
        year = safe_year(ws)
        ext_ids = extract_external_ids(ws)

        doi = ext_ids.get("doi")
        doi_url = format_doi_link(doi) if doi else None
        url = ext_ids.get("url")

        # publication type mapping (lightweight)
        wtype = (ws.get("type") or "").lower()
        pub_type = "article"
        if "conference" in wtype or "proceedings" in wtype:
            pub_type = "conference"
        elif "journal" in wtype:
            pub_type = "journal"
        elif "book" in wtype:
            pub_type = "book"

        slug = slugify(f"{year}-{title}")[:80]
        out_path = OUT_DIR / f"{slug}.md"

        # Hugo front matter (minimal, theme-friendly)
        front_matter = {
            "title": title,
            "date": f"{year}-01-01",
            "publication_types": [pub_type],
            "orcid": f"https://orcid.org/{ORCID_ID}",
            "autogen": AUTO_TAG,
        }

        lines = ["---"]
        for k, v in front_matter.items():
            if isinstance(v, list):
                lines.append(f"{k}: {json.dumps(v)}")
            else:
                lines.append(f'{k}: "{v}"')
        lines.append("---\n")

        # Body with links
        lines.append(f"**ORCID:** https://orcid.org/{ORCID_ID}\n")
        if doi_url:
            lines.append(f"[DOI]({doi_url})\n")
        if url and (not doi_url or url != doi_url):
            lines.append(f"[Link]({url})\n")

        # Add ScholarlyArticle JSON-LD (works even if theme doesnâ€™t support it)
        jsonld = {
            "@context": "https://schema.org",
            "@type": "ScholarlyArticle",
            "name": title,
            "datePublished": year,
            "identifier": [f"https://orcid.org/{ORCID_ID}"],
        }
        if doi:
            jsonld["sameAs"] = [doi_url] if doi_url else []
            jsonld["identifier"].append(f"DOI:{doi}")

        lines.append("\n<script type=\"application/ld+json\">")
        lines.append(json.dumps(jsonld, ensure_ascii=False))
        lines.append("</script>\n")

        out_path.write_text("\n".join(lines), encoding="utf-8")

    print(f"Generated publications from ORCID {ORCID_ID} into {OUT_DIR}")


if __name__ == "__main__":
    main()
